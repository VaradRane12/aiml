{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ba1a2487",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 9\u001b[39m\n\u001b[32m      6\u001b[39m \u001b[38;5;66;03m# --- Cell 1: Load and Split Data ---\u001b[39;00m\n\u001b[32m      8\u001b[39m categories = [\u001b[33m'\u001b[39m\u001b[33msci.med\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33msci.space\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m data = \u001b[43mfetch_20newsgroups\u001b[49m\u001b[43m(\u001b[49m\u001b[43msubset\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mall\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcategories\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcategories\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m42\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     11\u001b[39m X = data.data\n\u001b[32m     12\u001b[39m y = data.target\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Asus\\Documents\\Programming\\aiml\\.venv\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:218\u001b[39m, in \u001b[36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    212\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    213\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m    214\u001b[39m         skip_parameter_validation=(\n\u001b[32m    215\u001b[39m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m    216\u001b[39m         )\n\u001b[32m    217\u001b[39m     ):\n\u001b[32m--> \u001b[39m\u001b[32m218\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    219\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    220\u001b[39m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[32m    221\u001b[39m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[32m    222\u001b[39m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[32m    223\u001b[39m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[32m    224\u001b[39m     msg = re.sub(\n\u001b[32m    225\u001b[39m         \u001b[33mr\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mparameter of \u001b[39m\u001b[33m\\\u001b[39m\u001b[33mw+ must be\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    226\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc.\u001b[34m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m must be\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    227\u001b[39m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[32m    228\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Asus\\Documents\\Programming\\aiml\\.venv\\Lib\\site-packages\\sklearn\\datasets\\_twenty_newsgroups.py:320\u001b[39m, in \u001b[36mfetch_20newsgroups\u001b[39m\u001b[34m(data_home, subset, categories, shuffle, random_state, remove, download_if_missing, return_X_y, n_retries, delay)\u001b[39m\n\u001b[32m    318\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m download_if_missing:\n\u001b[32m    319\u001b[39m     logger.info(\u001b[33m\"\u001b[39m\u001b[33mDownloading 20news dataset. This may take a few minutes.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m320\u001b[39m     cache = \u001b[43m_download_20newsgroups\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    321\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtarget_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtwenty_home\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    322\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcache_path\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    323\u001b[39m \u001b[43m        \u001b[49m\u001b[43mn_retries\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    324\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdelay\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdelay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    325\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    326\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    327\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33m20Newsgroups dataset not found\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Asus\\Documents\\Programming\\aiml\\.venv\\Lib\\site-packages\\sklearn\\datasets\\_twenty_newsgroups.py:85\u001b[39m, in \u001b[36m_download_20newsgroups\u001b[39m\u001b[34m(target_dir, cache_path, n_retries, delay)\u001b[39m\n\u001b[32m     83\u001b[39m logger.debug(\u001b[33m\"\u001b[39m\u001b[33mDecompressing \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m\"\u001b[39m, archive_path)\n\u001b[32m     84\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m tarfile.open(archive_path, \u001b[33m\"\u001b[39m\u001b[33mr:gz\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m fp:\n\u001b[32m---> \u001b[39m\u001b[32m85\u001b[39m     \u001b[43mtarfile_extractall\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtarget_dir\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     87\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m suppress(\u001b[38;5;167;01mFileNotFoundError\u001b[39;00m):\n\u001b[32m     88\u001b[39m     os.remove(archive_path)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Asus\\Documents\\Programming\\aiml\\.venv\\Lib\\site-packages\\sklearn\\utils\\fixes.py:370\u001b[39m, in \u001b[36mtarfile_extractall\u001b[39m\u001b[34m(tarfile, path)\u001b[39m\n\u001b[32m    365\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mtarfile_extractall\u001b[39m(tarfile, path):\n\u001b[32m    366\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    367\u001b[39m         \u001b[38;5;66;03m# Use filter=\"data\" to prevent the most dangerous security issues.\u001b[39;00m\n\u001b[32m    368\u001b[39m         \u001b[38;5;66;03m# For more details, see\u001b[39;00m\n\u001b[32m    369\u001b[39m         \u001b[38;5;66;03m# https://docs.python.org/3/library/tarfile.html#tarfile.TarFile.extractall\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m370\u001b[39m         \u001b[43mtarfile\u001b[49m\u001b[43m.\u001b[49m\u001b[43mextractall\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mfilter\u001b[39;49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mdata\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    371\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[32m    372\u001b[39m         tarfile.extractall(path)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mE:\\Anaconda\\Lib\\tarfile.py:2352\u001b[39m, in \u001b[36mTarFile.extractall\u001b[39m\u001b[34m(self, path, members, numeric_owner, filter)\u001b[39m\n\u001b[32m   2347\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m tarinfo.isdir():\n\u001b[32m   2348\u001b[39m         \u001b[38;5;66;03m# For directories, delay setting attributes until later,\u001b[39;00m\n\u001b[32m   2349\u001b[39m         \u001b[38;5;66;03m# since permissions can interfere with extraction and\u001b[39;00m\n\u001b[32m   2350\u001b[39m         \u001b[38;5;66;03m# extracting contents can reset mtime.\u001b[39;00m\n\u001b[32m   2351\u001b[39m         directories.append(unfiltered)\n\u001b[32m-> \u001b[39m\u001b[32m2352\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_extract_one\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtarinfo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mset_attrs\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtarinfo\u001b[49m\u001b[43m.\u001b[49m\u001b[43misdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2353\u001b[39m \u001b[43m                      \u001b[49m\u001b[43mnumeric_owner\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnumeric_owner\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2354\u001b[39m \u001b[43m                      \u001b[49m\u001b[43mfilter_function\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfilter_function\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2356\u001b[39m \u001b[38;5;66;03m# Reverse sort directories.\u001b[39;00m\n\u001b[32m   2357\u001b[39m directories.sort(key=\u001b[38;5;28;01mlambda\u001b[39;00m a: a.name, reverse=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mE:\\Anaconda\\Lib\\tarfile.py:2455\u001b[39m, in \u001b[36mTarFile._extract_one\u001b[39m\u001b[34m(self, tarinfo, path, set_attrs, numeric_owner, filter_function)\u001b[39m\n\u001b[32m   2452\u001b[39m \u001b[38;5;28mself\u001b[39m._check(\u001b[33m\"\u001b[39m\u001b[33mr\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   2454\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m2455\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_extract_member\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtarinfo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mos\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m.\u001b[49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarinfo\u001b[49m\u001b[43m.\u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2456\u001b[39m \u001b[43m                         \u001b[49m\u001b[43mset_attrs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mset_attrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2457\u001b[39m \u001b[43m                         \u001b[49m\u001b[43mnumeric_owner\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnumeric_owner\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2458\u001b[39m \u001b[43m                         \u001b[49m\u001b[43mfilter_function\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfilter_function\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2459\u001b[39m \u001b[43m                         \u001b[49m\u001b[43mextraction_root\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2460\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mOSError\u001b[39;00m, \u001b[38;5;167;01mUnicodeEncodeError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m   2461\u001b[39m     \u001b[38;5;28mself\u001b[39m._handle_fatal_error(e)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mE:\\Anaconda\\Lib\\tarfile.py:2544\u001b[39m, in \u001b[36mTarFile._extract_member\u001b[39m\u001b[34m(self, tarinfo, targetpath, set_attrs, numeric_owner, filter_function, extraction_root)\u001b[39m\n\u001b[32m   2541\u001b[39m     \u001b[38;5;28mself\u001b[39m._dbg(\u001b[32m1\u001b[39m, tarinfo.name)\n\u001b[32m   2543\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m tarinfo.isreg():\n\u001b[32m-> \u001b[39m\u001b[32m2544\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmakefile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtarinfo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtargetpath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2545\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m tarinfo.isdir():\n\u001b[32m   2546\u001b[39m     \u001b[38;5;28mself\u001b[39m.makedir(tarinfo, targetpath)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mE:\\Anaconda\\Lib\\tarfile.py:2593\u001b[39m, in \u001b[36mTarFile.makefile\u001b[39m\u001b[34m(self, tarinfo, targetpath)\u001b[39m\n\u001b[32m   2591\u001b[39m source.seek(tarinfo.offset_data)\n\u001b[32m   2592\u001b[39m bufsize = \u001b[38;5;28mself\u001b[39m.copybufsize\n\u001b[32m-> \u001b[39m\u001b[32m2593\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mwith\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbltn_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtargetpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mwb\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mas\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   2594\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtarinfo\u001b[49m\u001b[43m.\u001b[49m\u001b[43msparse\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m:\u001b[49m\n\u001b[32m   2595\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43moffset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msize\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtarinfo\u001b[49m\u001b[43m.\u001b[49m\u001b[43msparse\u001b[49m\u001b[43m:\u001b[49m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# --- Cell 1: Load and Split Data ---\n",
    "\n",
    "categories = ['sci.med', 'sci.space']\n",
    "data = fetch_20newsgroups(subset='all', categories=categories, shuffle=True, random_state=42)\n",
    "\n",
    "X = data.data\n",
    "y = data.target\n",
    "target_names = data.target_names\n",
    "\n",
    "X_train_text, X_test_text, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# --- Cell 2: Vectorize Text Data ---\n",
    "\n",
    "vectorizer = CountVectorizer(stop_words='english')\n",
    "X_train = vectorizer.fit_transform(X_train_text).toarray()\n",
    "X_test = vectorizer.transform(X_test_text).toarray()\n",
    "\n",
    "# --- Cell 3: Train Naive Bayes ---\n",
    "\n",
    "alpha = 1.0 # Smoothing parameter\n",
    "n_samples, n_features = X_train.shape\n",
    "classes_ = np.unique(y_train)\n",
    "n_classes = len(classes_)\n",
    "\n",
    "class_log_prior_ = np.zeros(n_classes)\n",
    "feature_log_prob_ = np.zeros((n_classes, n_features))\n",
    "\n",
    "for i, c in enumerate(classes_):\n",
    "    X_c = X_train[y_train == c]\n",
    "    \n",
    "    # Calculate class log prior: log(P(c))\n",
    "    class_log_prior_[i] = np.log(X_c.shape[0] / n_samples)\n",
    "    \n",
    "    total_word_count_in_class = np.sum(X_c)\n",
    "    word_counts_in_class = np.sum(X_c, axis=0)\n",
    "    \n",
    "    # Calculate feature log probability with Laplace smoothing: log(P(w|c))\n",
    "    numerator = word_counts_in_class + alpha\n",
    "    denominator = total_word_count_in_class + alpha * n_features\n",
    "    \n",
    "    feature_log_prob_[i, :] = np.log(numerator / denominator)\n",
    "\n",
    "# --- Cell 4: Predict on Test Data ---\n",
    "\n",
    "# Calculate log probabilities for each class for all test samples\n",
    "# log(P(c|d)) = log(P(c)) + sum_w( log(P(w|c)) * count(w,d) )\n",
    "log_probs = X_test @ feature_log_prob_.T + class_log_prior_\n",
    "\n",
    "# Get the class with the highest log probability for each sample\n",
    "y_pred = classes_[np.argmax(log_probs, axis=1)]\n",
    "\n",
    "# --- Cell 5: Evaluate Performance ---\n",
    "\n",
    "# Calculate Accuracy\n",
    "accuracy = np.mean(y_test == y_pred)\n",
    "print(\"--- Model Evaluation Metrics ---\")\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "# Calculate Confusion Matrix\n",
    "cm_classes = np.unique(y_test)\n",
    "n_cm_classes = len(cm_classes)\n",
    "cm = np.zeros((n_cm_classes, n_cm_classes), dtype=int)\n",
    "\n",
    "for i in range(len(y_test)):\n",
    "    true_idx = np.where(cm_classes == y_test[i])[0][0]\n",
    "    pred_idx = np.where(cm_classes == y_pred[i])[0][0]\n",
    "    cm[true_idx, pred_idx] += 1\n",
    "\n",
    "print(\"\\n--- Confusion Matrix ---\")\n",
    "print(cm)\n",
    "\n",
    "# Calculate Classification Report\n",
    "precision = np.diag(cm) / np.sum(cm, axis=0)\n",
    "recall = np.diag(cm) / np.sum(cm, axis=1)\n",
    "f1_score = 2 * (precision * recall) / (precision + recall)\n",
    "support = np.sum(cm, axis=1)\n",
    "\n",
    "overall_accuracy = np.sum(np.diag(cm)) / np.sum(cm)\n",
    "\n",
    "avg_precision = np.mean(precision)\n",
    "avg_recall = np.mean(recall)\n",
    "avg_f1 = np.mean(f1_score)\n",
    "\n",
    "weighted_precision = np.sum(precision * support) / np.sum(support)\n",
    "weighted_recall = np.sum(recall * support) / np.sum(support)\n",
    "weighted_f1 = np.sum(f1_score * support) / np.sum(support)\n",
    "\n",
    "# --- Cell 6: Display Classification Report ---\n",
    "\n",
    "report = \"\\n--- Classification Report ---\\n\\n\"\n",
    "report += f\"{'':>10} {'precision':>10} {'recall':>10} {'f1-score':>10} {'support':>10}\\n\\n\"\n",
    "\n",
    "for i, name in enumerate(target_names):\n",
    "    report += f\"{name:>10} {precision[i]:10.4f} {recall[i]:10.4f} {f1_score[i]:10.4f} {support[i]:10}\\n\"\n",
    "    \n",
    "report += \"\\n\"\n",
    "report += f\"{'accuracy':>10} {'':>10} {'':>10} {overall_accuracy:10.4f} {np.sum(support):10}\\n\"\n",
    "report += f\"{'macro avg':>10} {avg_precision:10.4f} {avg_recall:10.4f} {avg_f1:10.4f} {np.sum(support):10}\\n\"\n",
    "report += f\"{'weighted avg':>10} {weighted_precision:10.4f} {weighted_recall:10.4f} {weighted_f1:10.4f} {np.sum(support):10}\\n\"\n",
    "\n",
    "print(report)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd1886f7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
