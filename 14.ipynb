{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "69cd2af9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello\n"
     ]
    }
   ],
   "source": [
    "print(\"hello\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "73bed529",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Running 5-Fold Cross-Validation ---\n",
      "Fold 1: MSE = 66,783,412.51 (RMSE = 8,172.11)\n",
      "Fold 2: MSE = 47,737,556.76 (RMSE = 6,909.24)\n",
      "Fold 3: MSE = 77,234,034.80 (RMSE = 8,788.29)\n",
      "Fold 4: MSE = 45,083,014.43 (RMSE = 6,714.39)\n",
      "Fold 5: MSE = 52,666,047.75 (RMSE = 7,257.14)\n",
      "\n",
      "--- Cross-Validation Results ---\n",
      "Average MSE: 57,900,813.25\n",
      "Average RMSE: 7,609.26\n",
      "Standard Deviation of MSE: 12,228,364.93\n",
      "\n",
      "--- Final Model (Trained on all data) ---\n",
      "Intercept (Base Salary Estimate): 98,747.54\n",
      "Coefficients (Impact on Salary):\n",
      "  experience: 17,451.86\n",
      "  education_PhD: 17,114.65\n",
      "  education_Bachelors: -15,853.47\n",
      "  primary_skill_Cloud: 6,104.12\n",
      "  primary_skill_SQL: -2,273.09\n",
      "  primary_skill_C++: -2,258.39\n",
      "  education_Masters: -1,261.18\n",
      "  primary_skill_Java: -1,220.59\n",
      "  primary_skill_Python: -352.05\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import warnings\n",
    "\n",
    "# Suppress warnings for cleaner output\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# --- 1. Generate Synthetic Data ---\n",
    "data_size = 200\n",
    "experience = np.random.uniform(0, 20, data_size)\n",
    "education_levels = ['Bachelors', 'Masters', 'PhD']\n",
    "education = np.random.choice(education_levels, data_size, p=[0.5, 0.3, 0.2])\n",
    "skills_list = ['Python', 'Java', 'C++', 'SQL', 'Cloud']\n",
    "\n",
    "# Generate 1-3 skills for each professional\n",
    "skills_raw = [np.random.choice(skills_list, np.random.randint(1, 4), replace=False) for _ in range(data_size)]\n",
    "# For simplicity in this model, we'll just use the *primary* skill (first one)\n",
    "# A more complex model might use multi-hot encoding\n",
    "primary_skill = [s[0] for s in skills_raw]\n",
    "\n",
    "# Define the relationship for salary\n",
    "# Base salary + coef*experience + education_bonus + skill_bonus + noise\n",
    "def education_bonus(e):\n",
    "    if e == 'Bachelors': return 0\n",
    "    if e == 'Masters': return 15000\n",
    "    if e == 'PhD': return 30000\n",
    "\n",
    "def skill_bonus(s):\n",
    "    if s == 'Python': return 5000\n",
    "    if s == 'Java': return 3000\n",
    "    if s == 'C++': return 4000\n",
    "    if s == 'SQL': return 2000\n",
    "    if s == 'Cloud': return 10000\n",
    "    return 0\n",
    "\n",
    "y = (50000 + # Base salary\n",
    "     3000 * experience + \n",
    "     np.array([education_bonus(e) for e in education]) +\n",
    "     np.array([skill_bonus(s) for s in primary_skill]) +\n",
    "     np.random.normal(0, 8000, data_size)) # Noise\n",
    "\n",
    "X = pd.DataFrame({\n",
    "    'experience': experience,\n",
    "    'education': education,\n",
    "    'primary_skill': primary_skill\n",
    "})\n",
    "\n",
    "# --- 2. Setup Preprocessing and Model Pipeline ---\n",
    "\n",
    "# Define which columns are numerical and which are categorical\n",
    "numerical_features = ['experience']\n",
    "categorical_features = ['education', 'primary_skill']\n",
    "\n",
    "# Create a preprocessor using ColumnTransformer\n",
    "# Numerical features will be scaled\n",
    "# Categorical features will be one-hot encoded\n",
    "preprocessor = make_column_transformer(\n",
    "    (StandardScaler(), numerical_features),\n",
    "    (OneHotEncoder(handle_unknown='ignore'), categorical_features)\n",
    ")\n",
    "\n",
    "# Create the full pipeline: preprocess, then regress\n",
    "pipeline = make_pipeline(\n",
    "    preprocessor,\n",
    "    LinearRegression()\n",
    ")\n",
    "\n",
    "# --- 3. Evaluate Performance using 5-Fold Cross-Validation ---\n",
    "n_splits = 5\n",
    "kf = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "# Use cross_val_score to get the scores for each fold\n",
    "# We use 'neg_mean_squared_error' because scikit-learn scoring is maximization-focused\n",
    "mse_scores_neg = cross_val_score(pipeline, X, y, cv=kf, scoring='neg_mean_squared_error')\n",
    "\n",
    "# Convert negative MSE scores to positive\n",
    "mse_scores = -mse_scores_neg\n",
    "\n",
    "print(f\"--- Running {n_splits}-Fold Cross-Validation ---\")\n",
    "for i, mse in enumerate(mse_scores):\n",
    "    print(f\"Fold {i+1}: MSE = {mse:,.2f} (RMSE = {np.sqrt(mse):,.2f})\")\n",
    "\n",
    "# --- 4. Display Final Results ---\n",
    "average_mse = np.mean(mse_scores)\n",
    "std_dev_mse = np.std(mse_scores)\n",
    "\n",
    "print(\"\\n--- Cross-Validation Results ---\")\n",
    "print(f\"Average MSE: {average_mse:,.2f}\")\n",
    "print(f\"Average RMSE: {np.sqrt(average_mse):,.2f}\")\n",
    "print(f\"Standard Deviation of MSE: {std_dev_mse:,.2f}\")\n",
    "\n",
    "# --- 5. Optional: Train Final Model and Inspect Coefficients ---\n",
    "final_model = pipeline.fit(X, y)\n",
    "\n",
    "# Get feature names after one-hot encoding\n",
    "try:\n",
    "    # Get the OneHotEncoder from the preprocessor\n",
    "    ohe = final_model.named_steps['columntransformer'].named_transformers_['onehotencoder']\n",
    "    # Get the feature names\n",
    "    ohe_feature_names = ohe.get_feature_names_out(categorical_features)\n",
    "    \n",
    "    # Combine numerical and categorical feature names\n",
    "    all_feature_names = numerical_features + list(ohe_feature_names)\n",
    "    \n",
    "    # Get coefficients\n",
    "    coefficients = final_model.named_steps['linearregression'].coef_\n",
    "    intercept = final_model.named_steps['linearregression'].intercept_\n",
    "\n",
    "    print(\"\\n--- Final Model (Trained on all data) ---\")\n",
    "    print(f\"Intercept (Base Salary Estimate): {intercept:,.2f}\")\n",
    "    print(\"Coefficients (Impact on Salary):\")\n",
    "    \n",
    "    # Pair names with coefficients\n",
    "    coef_df = pd.DataFrame({'Feature': all_feature_names, 'Coefficient': coefficients})\n",
    "    \n",
    "    # Sort by absolute value of coefficient for impact\n",
    "    coef_df['Abs_Coefficient'] = coef_df['Coefficient'].abs()\n",
    "    coef_df = coef_df.sort_values(by='Abs_Coefficient', ascending=False).drop(columns='Abs_Coefficient')\n",
    "    \n",
    "    for _, row in coef_df.iterrows():\n",
    "        print(f\"  {row['Feature']}: {row['Coefficient']:,.2f}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"\\nCould not retrieve feature names for coefficients: {e}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a828a6c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
